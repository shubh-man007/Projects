{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a8b7171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2ffde59b2d34e31879a191592ddd8c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/28.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd468d3864b24b3bba2478974f6e9934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/5.73M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26666a0107ef402a92a077aeb2b11d5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/32332 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of source sentence: 309\n",
      "Max length of target sentence: 274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch  0: 100%|███████████████████████████████████████████| 3638/3638 [6:04:33<00:00,  6.01s/it, loss=5.598]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: CHAPTER XIV\n",
      "TARGET: XIV\n",
      "PREDICTED: \n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Now, doctor, I shall take the liberty of administering a dose myself, on my own responsibility.\n",
      "TARGET: Ora, dottore, darei al malato una pozione di cui assumo tutta la responsabilità.\n",
      "PREDICTED: Non si , e la mia , e la mia vita .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch  1: 100%|███████████████████████████████████████████| 3638/3638 [5:56:15<00:00,  5.88s/it, loss=5.036]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: 'Seems indeed!\n",
      "TARGET: — Sì, ecco, vi pare!\n",
      "PREDICTED: — !\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: _Note_.—Three things I wanted exceedingly for this work—viz. a pickaxe, a shovel, and a wheelbarrow or basket; so I desisted from my work, and began to consider how to supply that want, and make me some tools.\n",
      "TARGET: Nota. — Per un tale lavoro mi mancavano alcune sustanzialissime cose, vale a dire, una zappa, una vanga, una carriuola, o almeno un canestro; laonde prima d’accingermi all’opera pensai al modo di supplire alla mancanza degl’indicati stromenti.\n",
      "PREDICTED: la mia vita , che mi , e la mia vita , e la mia vita , e la mia vita , e la mia vita , e la mia vita , e la mia vita , e la mia vita .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch  2: 100%|███████████████████████████████████████████| 3638/3638 [5:58:12<00:00,  5.91s/it, loss=5.833]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: For the first thing he weakened the Orsini and Colonnesi parties in Rome, by gaining to himself all their adherents who were gentlemen, making them his gentlemen, giving them good pay, and, according to their rank, honouring them with office and command in such a way that in a few months all attachment to the factions was destroyed and turned entirely to the duke.\n",
      "TARGET: E, la prima cosa, indebolí le parti Orsine e Colonnese in Roma; perché tutti li aderenti loro che fussino gentili uomini, se li guadagnò, facendoli sua gentili uomini e dando loro grandi provisioni; et onorolli, secondo le loro qualità, di condotte e di governi: in modo che in pochi mesi nelli animi loro l'affezione delle parti si spense, e tutta si volse nel duca.\n",
      "PREDICTED: E , per questo , per la sua vita , e , per la sua vita , e , per la sua vita , e la sua vita , e la sua vita , e la sua , e , e , e ' quali , e , , e ' quali , e ' quali , e ' quali , e , e ' quali , e ' , e ' , e ' , e ' quali , e ' quali , e ' , e ' quali , e ' , e ' , e ' , e ' quali li , e ' quali li , e ' quali li , e ' quali li , e ' quali li , e ' quali li , e ' quali , e ' quali li , e ' quali , e ' quali li , e ' quali , e ' quali li , e ' quali li , e ' quali , e ' quali li , e ' quali li , e ' quali li , e ' quali li , e ' quali , e ' loro , e ' quali , e ' quali , e ' quali , e ' quali , e ' quali , e ' quali li , e ' quali , e ' quali , , , , e ' quali , , e ' quali , e ' quali , e ' quali , e ' quali , e ' quali , e ' quali , e ' quali , e ' quali , e ' quali , e ' quali , e ' quali , e ' quali , e ' quali li , e ' quali , e ' quali , e ' quali , , , , , e ' quali , e\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: I learned, moreover, at intervals, and through broken and equivocal hints, another singular feature of his mental condition.\n",
      "TARGET: Appresi anche ad intervalli, e per certe confidenze troncate, per delle mezze parole, dei sottintesi, un'altra particolarità della sua situazione morale.\n",
      "PREDICTED: , e , e la sua vita , e la sua vita , la sua vita .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch  3: 100%|███████████████████████████████████████████| 3638/3638 [5:47:06<00:00,  5.72s/it, loss=5.049]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Now the idea of death no longer seemed so terrible and clear, and death itself no longer seemed inevitable.\n",
      "TARGET: Adesso anche il pensiero della morte non le sembrava più così terribile e chiaro, e la morte stessa non le appariva più inevitabile.\n",
      "PREDICTED: Ma il suo cuore non era più più più di più semplice e di più semplice , e non poteva .\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: I am now going to her,' he said in French, attentively watching Golenishchev's expression.\n",
      "TARGET: Vado da lei — disse in francese, guardando attento il viso di Golenišcev. —\n",
      "PREDICTED: Io sono venuto a parlare — disse , guardando con un sorriso di lacrime di lei .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch  4: 100%|███████████████████████████████████████████| 3638/3638 [5:43:13<00:00,  5.66s/it, loss=5.017]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: So it was this time.\n",
      "TARGET: Così fu anche quel giorno.\n",
      "PREDICTED: E questo era stato il tempo .\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: ANNA\n",
      "TARGET: Anna”\n",
      "PREDICTED: Anna Arkad ’ evna .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch  5: 100%|███████████████████████████████████████████| 3638/3638 [5:42:53<00:00,  5.66s/it, loss=4.551]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: \"Oh!\" you say, pausing at the door, \"I didn't know anybody was here.\"\n",
      "TARGET: — Ah! — esclamate, fermandovi sulla soglia — credevo che qui non ci fosse nessuno.\n",
      "PREDICTED: — Oh ! — esclamò , dopo aver guardato la porta , — non so nulla di qui .\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: For a mile or thereabouts my raft went very well, only that I found it drive a little distant from the place where I had landed before; by which I perceived that there was some indraft of the water, and consequently I hoped to find some creek or river there, which I might make use of as a port to get to land with my cargo.\n",
      "TARGET: Per un miglio all’incirca la mia zattera andò assai bene; trovai solamente che nel dirigersi verso il lido si scostava alcun poco dal luogo ove presi terra la prima volta, la qual cosa ben mi fece conoscere esservi qualche braccio di mare che s’internava nella costa, onde concepii la speranza di trovare quivi un seno o un fiume, che mi facesse uffizio di porto per isbarcare tutta la mia provvigione.\n",
      "PREDICTED: Per un miglio o un miglio , non mi riuscì a bordo , perchè io non mi trovai più di terra , che io m ’ avea fatto un ’ altra volta , e che io era stato un ’ altra volta , e che io avessi fatto un ’ altra volta , e che per un vascello o di mare .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch  6: 100%|███████████████████████████████████████████| 3638/3638 [5:37:33<00:00,  5.57s/it, loss=3.909]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: I confess this side of the country was much pleasanter than mine; but yet I had not the least inclination to remove, for as I was fixed in my habitation it became natural to me, and I seemed all the while I was here to be as it were upon a journey, and from home.\n",
      "TARGET: Devo confessare che questa banda di paese era più piacevole della mia; ciò non ostante non mi venne la menoma voglia di traslocarmi. Mi era già stabilito nella mia abitazione, mi vi era affezionato, onde per tutto il tempo che rimasi quivi mi considerai sempre come un uomo in viaggio e fuori di casa propria.\n",
      "PREDICTED: Io , per questo , il mio lavoro era stato più grande , ma non mi riuscì a , come mi era stato fatto in me il mio destino , che il mio destino era stato in un viaggio di casa , e che in questo tempo mi fossi stato fatto in un viaggio .\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: \"Fire rises out of the lunar mountains: when she is cold, I'll carry her up to a peak, and lay her down on the edge of a crater.\"\n",
      "TARGET: — Nella luna il fuoco esce dalle montagne; quando avrà freddo la porterò in vetta a un monte e la metterò sull'orlo di un cratere.\n",
      "PREDICTED: — di , quando la luna è aperta , e io non ne vado fuori un ' occhiata e mi di sotto un .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch  7: 100%|███████████████████████████████████████████| 3638/3638 [5:36:34<00:00,  5.55s/it, loss=4.019]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: \"No; none that I ever saw.\" \"And your home?\" \"I have none.\"\n",
      "TARGET: — No, nessuno che conosca. — Dove stanno? — Non ne ho.\n",
      "PREDICTED: — No , non ho mai visto , — pensavo , — e non ho mai veduto .\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: I see the necessity of departure; and it is like looking on the necessity of death.\"\n",
      "TARGET: Vedo la necessità della separazione, che mi si presenta come la necessità della morte.\n",
      "PREDICTED: Lo vedo la questione della partenza e la morte è come la morte .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch  8: 100%|███████████████████████████████████████████| 3638/3638 [5:39:11<00:00,  5.59s/it, loss=3.681]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: I went up to him to try and save him.\n",
      "TARGET: Corsi da lui per tentar di salvarlo.\n",
      "PREDICTED: Lo seguii per fargli capire che gli avrei .\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: 'And ever since that,' the Hatter went on in a mournful tone, 'he won't do a thing I ask!\n",
      "TARGET: — E d'allora, — continuò melanconicamente il Cappellaio, — il tempo non fa più nulla di quel che io voglio!\n",
      "PREDICTED: — E in quel momento , — continuò il Cappellaio , — non è possibile che dire .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch  9: 100%|███████████████████████████████████████████| 3638/3638 [5:38:46<00:00,  5.59s/it, loss=4.340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: She seemed to want no company; no conversation. I believe she was happy in her way: this routine sufficed for her; and nothing annoyed her so much as the occurrence of any incident which forced her to vary its clockwork regularity.\n",
      "TARGET: Pareva che non sentisse il desiderio di parlare né di veder gente; era felice a modo suo e nulla l'annoiava tanto quanto una circostanza qualsiasi che le impedisse di mantenere la regolarità delle sue occupazioni.\n",
      "PREDICTED: Non voleva desiderare altro che una conversazione , ma non credo che fosse felice né felice , né lei , né , né lei , né lei , né avrebbe potuto .\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: \"Yes, sir,\" replied the genial old fellow. \"I caught him just below the lock - leastways, what was the lock then - one Friday afternoon; and the remarkable thing about it is that I caught him with a fly.\n",
      "TARGET: — Sì, signore — rispose il vecchio con genialità. — L’acchiappai proprio sotto la chiusa, per lo meno ciò che era la chiusa allora... un venerdì di pomeriggio; e la più strana cosa si è che che l’acchiappai con una mosca.\n",
      "PREDICTED: — Sì , signore , — rispose il vecchio , — che lo in un punto di chiusa , come un pomeriggio ; e che un pomeriggio fu bello strano , mi in un pomeriggio .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch  10: 100%|██████████████████████████████████████████| 3638/3638 [5:36:47<00:00,  5.55s/it, loss=3.406]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Anna had already returned.\n",
      "TARGET: Anna era già a casa.\n",
      "PREDICTED: Anna era già giunta a casa , se n ’ era già tornato .\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: And for the first time the clear idea occurred to him that it was necessary to put an end to all this falsehood, and the sooner the better.\n",
      "TARGET: Così per la prima volta gli apparve chiaro nella mente il pensiero che fosse indispensabile porre termine a quella menzogna, e che quanto prima ciò sarebbe accaduto tanto meglio sarebbe stato.\n",
      "PREDICTED: E per la prima volta , per quanto egli fosse necessario , che bisognava una volta a un po ’ da parte , e questa faccenda , anche se stesso , la cosa meglio , la cosa più meglio .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch  11: 100%|██████████████████████████████████████████| 3638/3638 [5:36:30<00:00,  5.55s/it, loss=3.445]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: My thoughts kept me awake.\n",
      "TARGET: I pensieri me lo impedivano.\n",
      "PREDICTED: I miei pensieri mi parvero quasi senza nulla .\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Our feet were undoubtedly the leading article in that photograph.\n",
      "TARGET: Indubbiamente i nostri piedi erano in quella fotografia l’oggetto principale.\n",
      "PREDICTED: I nostri piedi erano stati dall ’ aspetto che gli si .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch  12: 100%|██████████████████████████████████████████| 3638/3638 [5:37:32<00:00,  5.57s/it, loss=1.609]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: She paused, unable to invent a reason.\n",
      "TARGET: Si fermò non trovando nessuna giustificazione.\n",
      "PREDICTED: Ella si fermò , non senza dubbio , non riuscì a .\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Vronsky respected and liked Yashvin, particularly because he felt that the latter liked him, not for his name and money but for himself.\n",
      "TARGET: Vronskij lo stimava e gli voleva bene soprattutto perché sentiva che Jašvin gliene voleva non per il suo nome o per la sua ricchezza, ma per la sua persona.\n",
      "PREDICTED: Vronskij amava e lui , soprattutto , sentiva che il suo nome , che gli era stato offerto di lui , e non perché gli era suo nome e per lui .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch  13: 100%|██████████████████████████████████████████| 3638/3638 [5:39:12<00:00,  5.59s/it, loss=3.508]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: CHAPTER XII.\n",
      "TARGET: CAPITOLO XII.\n",
      "PREDICTED: XII .\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: The merchant in London, vesting this hundred pounds in English goods, such as the captain had written for, sent them directly to him at Lisbon, and he brought them all safe to me to the Brazils; among which, without my direction (for I was too young in my business to think of them), he had taken care to have all sorts of tools, ironwork, and utensils necessary for my plantation, and which were of great use to me.\n",
      "TARGET: Il mercante di Londra, dopo avere convertite le cento lire sterline in merci di manifattura inglese, quali gliele aveva indicate il mio amico, le inviò direttamente a Lisbona, onde il capitano me le portò poi intatte al Brasile. Fra queste (e certo senza ch’io gliene avessi fatto cenno, che era troppo giovine per intendermi di tali affari) aveva avuto cura di far sì che si trovasse ogni sorta di stromenti, ferramenti ed ordigni necessari alla mia piantagione, e riconosciuti di grand’uso per me.\n",
      "PREDICTED: La nostra navigazione dall ’ Inghilterra , onde gli aveva scritto come gli aveva scritto in questi luoghi e , tutti i loro primi a Lisbona , li aveva tutti i lavori di un ’ impresa che non era affatto per me ; ed al Brasile , tuttavia dalla parte dei lavori di ed di ed di , di anch ’ io per me , per me ne aveva di ed di ed di .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch  14: 100%|██████████████████████████████████████████| 3638/3638 [5:38:41<00:00,  5.59s/it, loss=2.395]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: And they started something like a game which consisted in trying to get as close to her as possible, to touch her, hold her little hand, kiss her, play with her ring, or at least touch the frills of her dress.\n",
      "TARGET: E fra di loro si era venuto a formare come una specie di giuoco che consisteva nello star seduti il più vicino possibile a lei, nel toccarla, nel tenere tra le proprie la sua piccola mano, nel baciarla, nel giocar con l’anello suo, o nel toccare almeno la gala del suo vestito.\n",
      "PREDICTED: E si misero a parlare di un telegramma , che , per quanto possibile , si fosse possibile , la mano , la , la baciò vestita , con la e il vestito , per il vestito , per il vestito , le preoccupazioni per la schiena .\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: King John has slept at Duncroft Hall, and all the day before the little town of Staines has echoed to the clang of armed men, and the clatter of great horses over its rough stones, and the shouts of captains, and the grim oaths and surly jests of bearded bowmen, billmen, pikemen, and strange-speaking foreign spearmen.\n",
      "TARGET: Re Giovanni ha dormito a Duncroft Hall, e tutto il giorno prima la piccola città di Staines ha echeggiato del tintinnio di uomini armati, del calpestio di grandi cavalli sullo scabro selciato, delle grida dei condottieri, delle paurose bestemmie, e degli acri motteggi di barbuti arceri, alabardieri e lanceri che si esprimono in istrane favelle.\n",
      "PREDICTED: Il Re ha trovato nella sala da pranzo e tutta la giornata del giorno innanzi a tutti i cavalli da nolo , l ' aria di trattare con i cavalli di cavalli , e i grandi che sono , le altre , le , le , o le altre di qualità , o bestie ben terribile , o bestie sono terribile .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch  15: 100%|██████████████████████████████████████████| 3638/3638 [5:38:57<00:00,  5.59s/it, loss=2.618]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: They explained to him that they had thought he was some one they knew. They said they hoped he would not deem them capable of so insulting any one except a personal friend of their own.\n",
      "TARGET: Spiegarono al giovane che lo avevano scambiato per uno di loro conoscenza, dicendo che speravano non li stimasse capaci d’insultare chiunque non fosse un loro amico personale.\n",
      "PREDICTED: Gli che avevano pensato che , evidentemente , era una cosa sola , dissero che non avrebbe voluto che un ’ opinione così di lui , oltre a un amico , oltre la propria posizione .\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: When a lady, young and full of life and health, charming with beauty and endowed with the gifts of rank and fortune, sits and smiles in the eyes of a gentleman you--\"\n",
      "TARGET: Quando una donna giovane e bella, piena di vita e di salute, dotata di tutte le prerogative della nascita e della ricchezza, sorride a un uomo, voi....\n",
      "PREDICTED: Quando una ragazza , una signorina e tutta la salute , e noi sono brava gente , e voi dovete dimenticare e voi ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch  16: 100%|██████████████████████████████████████████| 3638/3638 [5:35:59<00:00,  5.54s/it, loss=2.553]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: As horses were also required for the Princess, who was leaving, and for the midwife, it was inconvenient to Levin; but he could not be so inhospitable as to allow Dolly to hire horses while staying with him. Besides, he knew that the twenty roubles she would have had to pay for the journey were of importance to her, and he felt her distressing financial embarrassments as if they had been his own.\n",
      "TARGET: In quel momento, in cui i cavalli servivano e per la principessa che partiva e per la levatrice, la cosa era stata difficile per Levin, ma per dovere di ospitalità egli non poteva permettere a Dar’ja Aleksandrovna di noleggiare i cavalli, inoltre, sapeva che i venti rubli che le avrebbero chiesto per quel viaggio avevano grande peso per lei, e le faccende finanziarie di Dar’ja Aleksandrovna, così dissestate, erano sentite dai Levin come loro proprie.\n",
      "PREDICTED: Per i cavalli , la principessa era andata a prendere il denaro per la principessa e per il denaro che era stato venduto a Levin ; ma Levin non poteva riconoscere il contadino con la stessa quota di cavalli , sapeva che sotto il viaggio sarebbe stato compiuto da lui per venti rubli in quel viaggio . E da come se lo avessero saputo del viaggio , era stato un viaggio penoso .\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: On one point we were all agreed, and that was that, come what might, we would go through with this job to the bitter end.\n",
      "TARGET: Su un punto eravamo tutti d’accordo, e cioè, che, qualunque cosa avvenisse, avremmo fatto il nostro dovere fino all’amara fine.\n",
      "PREDICTED: In una situazione straordinaria era affatto occupato , e che fosse accaduto , la conseguenza si sarebbe potuto andar giù dal lavoro .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch  17: 100%|██████████████████████████████████████████| 3638/3638 [5:33:50<00:00,  5.51s/it, loss=2.415]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: AFTER BREAKFAST LEVIN GOT PLACED between a humorous old man who invited him to be his neighbour and a young peasant who had only got married last autumn and was now out for his first summer's mowing.\n",
      "TARGET: Dopo la colazione, Levin non capitò più, nella fila, al posto di prima, ma fra il vecchio scherzoso che l’aveva invitato ad essere suo vicino e il contadino giovane, sposato solo dall’autunno, e che era venuto a falciare per la prima volta.\n",
      "PREDICTED: Dopo aver passeggiato per il vecchio e un amico , dopo aver fatto per essere un giovanotto e un giovane che adesso aveva provato per il primo incontro , e aveva cominciato a falciare nel primo prato nuovo .\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: \"Burns, you poke your chin most unpleasantly; draw it in.\" \"Burns, I insist on your holding your head up; I will not have you before me in that attitude,\" &c. &c.\n",
      "TARGET: Burns, vi ho detto di tener la testa diritta; non voglio vedervi davanti a me in quell'atteggiamento.\n",
      "PREDICTED: — Elena , l ' avete del vostro mento ; ho cercato di con voi la testa , — continuai a dire : — Non avrò altro che quel suo aspetto di pace .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch  18: 100%|██████████████████████████████████████████| 3638/3638 [5:26:44<00:00,  5.39s/it, loss=2.503]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: I'll furnish my own wardrobe out of that money, and you shall give me nothing but--\"\n",
      "TARGET: Voglio provvedere del mio alle spese di vestiario, e voi non mi darete nulla, altro....\n",
      "PREDICTED: Io al mio posto di questo albergo , e voi mi a voi ...\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Mr. Rochester has a wife now living.\"\n",
      "TARGET: Il signor Rochester ha una moglie tuttora viva.\n",
      "PREDICTED: Il signor Rochester ha bisogno di vivere .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch  19: 100%|██████████████████████████████████████████| 3638/3638 [5:15:43<00:00,  5.21s/it, loss=2.394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: After living in Moscow, especially in the bosom of his family, Oblonsky always felt his spirits flag.\n",
      "TARGET: Dopo aver vissuto un po’ a Mosca, specialmente vicino alla famiglia, sentiva che andava giù di umore.\n",
      "PREDICTED: Dopo di Mosca , in particolare nel cuore , Stepan Arkad ’ ic , in gran parte della sua famiglia , si sentiva sempre le sue .\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Bessie is not sure whether she is in her right mind, or means anything by the words; but she told Miss Reed and Miss Georgiana, and advised them to send for you.\n",
      "TARGET: Bessie non era sicura che avesse la testa a posto e desiderasse davvero di parlarvi; ma ha raccontato alle signorine quello che era accaduto ed ha consigliato loro di farvi chiamare.\n",
      "PREDICTED: Bessie non è certo modo , o almeno è in coscienza , o le mie parole : ella disse , e la signorina Georgiana , che vi hanno detto per .\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "from dataset import BilingualDataset, causal_mask\n",
    "from model import build_transformer\n",
    "from config import get_weights_file_path, get_config\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from datasets import load_dataset\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def greedy_decode(model, source, source_mask, tokenizer_src, tokenizer_tgt, max_len, device):\n",
    "    sos_idx = tokenizer_tgt.token_to_id('[SOS]')\n",
    "    eos_idx = tokenizer_tgt.token_to_id('[EOS]')\n",
    "\n",
    "    # Precompute the encoder output and reuse it for every step\n",
    "    encoder_output = model.encode(source, source_mask)\n",
    "    # Initialize the decoder input with the sos token\n",
    "    decoder_input = torch.empty(1, 1).fill_(sos_idx).type_as(source).to(device)\n",
    "    while True:\n",
    "        if decoder_input.size(1) == max_len:\n",
    "            break\n",
    "\n",
    "        # build mask for target\n",
    "        decoder_mask = causal_mask(decoder_input.size(1)).type_as(source_mask).to(device)\n",
    "\n",
    "        # calculate output\n",
    "        out = model.decode(encoder_output, source_mask, decoder_input, decoder_mask)\n",
    "\n",
    "        # get next token\n",
    "        prob = model.project(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        decoder_input = torch.cat(\n",
    "            [decoder_input, torch.empty(1, 1).type_as(source).fill_(next_word.item()).to(device)], dim=1\n",
    "        )\n",
    "\n",
    "        if next_word == eos_idx:\n",
    "            break\n",
    "\n",
    "    return decoder_input.squeeze(0)\n",
    "\n",
    "\n",
    "\n",
    "def run_validation(model, validation_ds, tokenizer_src, tokenizer_tgt, max_len, device, print_msg, global_state, writer, num_examples = 2):\n",
    "    model.eval()\n",
    "    count = 0\n",
    "    console_width = 80\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in validation_ds:\n",
    "            count += 1\n",
    "            encoder_input = batch['encoder_input'].to(device)\n",
    "            encoder_mask = batch['encoder_mask'].to(device)\n",
    "\n",
    "            assert encoder_input.size(0) == 1, \"Batch size must be 1 for validation\"\n",
    "\n",
    "            model_out = greedy_decode(model, encoder_input, encoder_mask, tokenizer_src, tokenizer_tgt, max_len, device)\n",
    "\n",
    "            source_text = batch['src_text'][0]\n",
    "            target_text = batch['tgt_text'][0]\n",
    "            model_out_text = tokenizer_tgt.decode(model_out.detach().cpu().numpy())\n",
    "\n",
    "            print_msg('-'*console_width)\n",
    "            print_msg(f'SOURCE: {source_text}')\n",
    "            print_msg(f'TARGET: {target_text}')\n",
    "            print_msg(f'PREDICTED: {model_out_text}')\n",
    "\n",
    "            if count == num_examples:\n",
    "                break\n",
    "\n",
    "\n",
    "def get_all_sentences(ds, lang):\n",
    "    for item in ds:\n",
    "        yield item['translation'][lang]\n",
    "\n",
    "\n",
    "\n",
    "def get_or_build_tokenizer(config, ds, lang):\n",
    "    tokenizer_path = Path(config['tokenizer_file'].format(lang))\n",
    "    if not Path.exists(tokenizer_path):\n",
    "        tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
    "        tokenizer.pre_tokenizer = Whitespace()\n",
    "        trainer = WordLevelTrainer(special_tokens=[\"[UNK]\", \"[PAD]\", \"[SOS]\", \"[EOS]\"], min_frequency=2)\n",
    "        tokenizer.train_from_iterator(get_all_sentences(ds, lang), trainer=trainer)\n",
    "        tokenizer.save(str(tokenizer_path))\n",
    "    else:\n",
    "        tokenizer = Tokenizer.from_file(str(tokenizer_path))\n",
    "    return tokenizer\n",
    "\n",
    "\n",
    "\n",
    "def get_ds(config):\n",
    "    ds_raw = load_dataset('opus_books', f'{config[\"lang_src\"]}-{config[\"lang_tgt\"]}', split = 'train')\n",
    "\n",
    "    tokenizer_src = get_or_build_tokenizer(config, ds_raw, config['lang_src'])\n",
    "    tokenizer_tgt = get_or_build_tokenizer(config, ds_raw, config['lang_tgt'])\n",
    "\n",
    "    train_ds_size = int(0.9 * len(ds_raw))\n",
    "    val_ds_size = len(ds_raw) - train_ds_size\n",
    "    train_ds_raw, val_ds_raw = random_split(ds_raw, [train_ds_size, val_ds_size])\n",
    "\n",
    "    train_ds = BilingualDataset(train_ds_raw, tokenizer_src, tokenizer_tgt, config['lang_src'], config['lang_tgt'], config['seq_len'])\n",
    "    val_ds = BilingualDataset(val_ds_raw, tokenizer_src, tokenizer_tgt, config['lang_src'], config['lang_tgt'], config['seq_len'])\n",
    "\n",
    "    max_len_src = 0\n",
    "    max_len_tgt = 0\n",
    "\n",
    "    for item in ds_raw:\n",
    "        src_ids = tokenizer_src.encode(item['translation'][config['lang_src']]).ids\n",
    "        tgt_ids = tokenizer_tgt.encode(item['translation'][config['lang_tgt']]).ids\n",
    "        max_len_src = max(max_len_src, len(src_ids))\n",
    "        max_len_tgt = max(max_len_tgt, len(tgt_ids))\n",
    "\n",
    "    print(f'Max length of source sentence: {max_len_src}')\n",
    "    print(f'Max length of target sentence: {max_len_tgt}')\n",
    "\n",
    "    train_dataloader = DataLoader(train_ds, batch_size = config['batch_size'], shuffle = True)\n",
    "    val_dataloader = DataLoader(val_ds, batch_size = 1, shuffle = True)\n",
    "\n",
    "    return train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt\n",
    "\n",
    "\n",
    "\n",
    "def get_model(config, vocab_src_len, vocab_tgt_len):\n",
    "    model = build_transformer(vocab_src_len, vocab_tgt_len, config[\"seq_len\"], config['seq_len'], d_model=config['d_model'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def train_model(config):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Using device {device}')\n",
    "\n",
    "    Path(config['model_folder']).mkdir(parents = True, exist_ok = True)\n",
    "\n",
    "    train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt = get_ds(config)\n",
    "    model = get_model(config, tokenizer_src.get_vocab_size(), tokenizer_tgt.get_vocab_size()).to(device)\n",
    "\n",
    "    writer = SummaryWriter(config['experiment_name'])\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = config['lr'], eps = 1e-9)\n",
    "\n",
    "    initial_epoch = 0\n",
    "    global_step = 0\n",
    "\n",
    "    if config['preload']:\n",
    "        model_filename = get_weights_file_path(config, config['preload'])\n",
    "        print(f'Preloading model {model_filename}')\n",
    "        state = torch.load(model_filename)\n",
    "        initial_epoch = state['epoch'] + 1\n",
    "        optimizer.load_state_dict(state['optimizer_state_dict'])\n",
    "        global_step = state['global_step']\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss(ignore_index = tokenizer_src.token_to_id('[PAD]'), label_smoothing = 0.1).to(device)\n",
    "\n",
    "    for epoch in range(initial_epoch, config['num_epochs']):\n",
    "        batch_iterator = tqdm(train_dataloader, desc = f'Processing epoch {epoch : 02d}')\n",
    "\n",
    "        for batch in batch_iterator:\n",
    "            model.train()\n",
    "\n",
    "            encoder_input = batch['encoder_input'].to(device)\n",
    "            decoder_input = batch['decoder_input'].to(device)\n",
    "            encoder_mask = batch['encoder_mask'].to(device)\n",
    "            decoder_mask = batch['decoder_mask'].to(device)\n",
    "\n",
    "            encoder_output = model.encode(encoder_input, encoder_mask)\n",
    "            decoder_output = model.decode(encoder_output, encoder_mask, decoder_input, decoder_mask)\n",
    "            proj_output = model.project(decoder_output)\n",
    "\n",
    "            label = batch['label'].to(device)\n",
    "\n",
    "            loss = loss_fn(proj_output.view(-1, tokenizer_tgt.get_vocab_size()), label.view(-1))\n",
    "            batch_iterator.set_postfix({f\"loss\": f\"{loss.item():6.3f}\"})\n",
    "\n",
    "            writer.add_scalar('train_loss', loss.item(), global_step)\n",
    "            writer.flush()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            global_step += 1\n",
    "\n",
    "        run_validation(model, val_dataloader, tokenizer_src, tokenizer_tgt, config['seq_len'], device, lambda msg: batch_iterator.write(msg), global_step, writer)\n",
    "\n",
    "        model_filename = get_weights_file_path(config, f'{epoch : 02d}')\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'global_step': global_step\n",
    "        }, model_filename)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    warnings.filterwarnings('ignore')\n",
    "    config = get_config()\n",
    "    train_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c3444f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
